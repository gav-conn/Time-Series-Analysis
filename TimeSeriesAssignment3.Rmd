---
title: "Time Series Analysis Assignment 3"
author: "Gavin Connolly"
date: "15/11/2021"
output: html_document
---

```{r setup, include=FALSE}
library("forecast")
library("TSA")
library("lmtest")
```

Read in the 3 time series in the file “assignment3.csv” using series=read.csv('assignment3.csv') and answer the following questions.

```{r Data Import}
series=read.csv('assignment3.csv')
X = series[,1]
Y = series[,2]
Z = series[,3]
```

## Exercise 1

#### a) For Series X, identify the number of differences (if any) and order of the ARMA model for the stationary series based on the results of tsdisplay(). Give reasons for your answers.

```{r Examine ACF/PACF plots of X}
tsdisplay(X) # ACF & PACF decay slowly indicating our time series is integrated
```
As the ACF seems to be decaying linearly & both ACF/PACF decay slowly, we conclude that the time series is integrated. We therefore look to difference the series before continuing.

```{r pressure}
dX = diff(X)
tsdisplay(dX)
# ACF null after lag of 1. PACF decays exponentially.
# dX is MA(1). with theta roughly equal to 0.5
# X is ARIMA(0, 1, 1)
```

We see that the ACF plot of the integrated series dX is null after a lag of 1, while the PACF decays exponentially, indicating that the differenced series is ARMA(0, 1).

We thus conclude that Series X is generated by an ARIMA(0, 1, 1) model.

#### b) For Series Y, identify the number of differences (if any) and order of the ARMA model for the stationary series based on the results of tsdisplay(). Give reasons for your answers.

```{r ACF/PACF of Y}
tsdisplay(Y)
```

We see that the ACF plot for Y decays exponentially while the PACF is null after a lag of 2. 
As neither the ACF/PACF plots decay linearly we know the series is not integrated. 

We therefore conclude that the series is AR(2).

#### c) Report the AR and/or MA parameter estimates for Series X and Y, with no drift by using include.mean=FALSE. Are they statistically significant?

```{r Estimate model parameters for X}
modelX = arima(X, order = c(0,1,1), include.mean = FALSE)
coeftest(modelX)
# Pr(>|Z|) = 2.2e-16, so parameter estimate is significant.
```

We calculate $\theta_1$ to be -0.8248, with a p-value of 0. We therefore conclude that the model parameters are significant.

```{r Estimate model parameters for Y}
modelY = arima(Y, order = c(2,0,0), include.mean = FALSE)
coeftest(modelY)
# Pr(>|phi1|) = 7.9833e-16 & Pr(>|phi2|) = 1.55e-09, so parameter estimates are significant.
```

We calculate $\phi_1$ to be 0.3471 & $\phi_2$ to be 0.2602, with a p-value of roughly 0 for each. We therefore conclude that each of the model parameters are significant.

#### d) Look at Series Z. What type of model should you choose and why? Again, focus on models without drift (i.e. mean zero).

```{r Examine ACF/PACF of Z}
tsdisplay(Z)
```

ACF/PACF plots for Z both tail off, indicating that we should use an ARMA process for the time series.

#### e) Now try ARMA(1,1), ARMA(1,2) and ARMA(2,1) models fit to Series Z. Do the parameters come out to be statistically significant? Why?

```{r Fit ARMA(1,1)}
modelZ1 = arima(Z, order = c(1, 0, 1), include.mean = FALSE)
coeftest(modelZ1) # coefficients are significant
```

Coefficients for the ARMA(1,1) model are all significant.

```{r Fit ARMA(1,2)}
modelZ2 = arima(Z, order = c(1, 0, 2), include.mean = FALSE)
coeftest(modelZ2) #AR1 & MA1 coefficients are significant, MA2 coefficient is not significant
```

$\phi_1$ & $\theta_1$ coefficients for the ARMA(1,2) model are significant, while the $\theta_2$ coefficient is not significant. This is because the model is overfitting the data, meaning that the parameter is not needed in the model, and therefore its value is not significantly different from 0.

```{r Fit ARMA(2),1)}
modelZ3 = arima(Z, order = c(2, 0, 1), include.mean = FALSE)
coeftest(modelZ3) # AR1 & MA1 coefficients are significant, AR2 coefficient is not significant
# We get significant coefficients for AR1 & MA1 terms as the time series is generated by an ARMA(1,1)
# We get non-significant coefficients for the AR2 & MA2 terms as they overfit the model, meaning they are not significantly different from 0
```

Once again, the $\phi_1$ & $\theta_1$ coefficients for the ARMA(2,1) model are significant, but the $\phi_2$ coefficient is not significant.
This is because the model is overfitting the data, meaning that the parameter is not needed in the model, and therefore its value is not significantly different from 0.

## Exercise 2

We will now examine model fit for Series Z in more detail.

#### a) Examine the residuals of an ARMA(1,1) model fit to Series Z and describe what you find.

```{r Examine residuals of ARMA(1,1)}
res1 = residuals(modelZ1)
plot(res1)
mean(res1)
var(res1)
```

Plot of residuals looks to be distributed as a white noise. Mean of residuals roughly 0 & variance roughly 1.

```{r Look at qq plot to examine normality}
qqnorm(res1)
qqline(res1)
```

```{r Run Shapriro test}
shapiro.test(res1)
# p-value of 0.2032, fail to reject normality hypothesis at 5% significance
```

QQ-Plot seems fine as well, p-value on the Shapiro-Wilk test of 0.2032 means we do not reject the normality hypothesis on the residuals at 5% significance level.

```{r Plot residuals}
plot(res1, fitted(modelZ1)) # no obvious pattern in residuals
```

There is no obvious pattern in the plot of residuals vs fitted values.

```{r Look at ACF plot of residuals}
acf(res1) # acf of residuals null for all lags
```

ACF of residuals is null for all lags, indicating we have chosen a large enough value of q & that our residuals are not correlated with themselves.

```{r Run Ljung-Box test}
Box.test(res1, lag = 12, type = "Ljung-Box", fitdf = 2)
# p-value = 0.3781. Fail to reject hypothesis that residuals distributed as a white noise.
```

Ljung-Box test reports a p-value of 0.4029, meaning we fail to reject hypothesis that residuals are distributed as a white noise.

```{r Examine PACF of residuals}
pacf(res1)# pacf of residuals null for all lags
```

PACF plot shows null values for all lags, indicating that our choice of p is large enough.

#### b) Examine the residuals of an AR(2) model fit to Series Z and describe what you find.

```{r look at residuals of AR(2) model}
modelAR2 = arima(Z, order = c(2,0,0), include.mean = FALSE)
resAR2 = residuals(modelAR2)
plot(resAR2)
```

```{r calculate mean/var}
mean(resAR2)
var(resAR2)
```

Plot of residuals looks to be distributed as a white noise. Mean of residuals roughly 0 & variance roughly 1.28.

```{r Examine qq-plot for AR2}
qqnorm(resAR2)
qqline(resAR2)
```
```{r run shapiro test}
shapiro.test(resAR2) # p-value of 0.6861. Fail to reject normality hypothesis
```

QQ-Plot seems fine as well, p-value on the Shapiro-Wilk test of 0.6861 means we do not reject the normality hypothesis on the residuals at 5% significance level.

```{r plot residuals to look for patterns}
plot(resAR2, fitted(modelAR2)) # no obvious pattern in residuals
```

There is no obvious pattern in the plot of residuals vs fitted values.

```{r Look at ACF plot for AR2}
acf(resAR2) # ACF not null for lags less than 5 time steps
```
```{r Run box test for AR2}
Box.test(resAR2, lag = 12, type = "Ljung-Box", fitdf = 2) 
# p-value = 5.285e-11. Reject hypothesis that residuals distributed as a white noise.
```

ACF plot of residuals shows that there is non-null autocorrelation for lags less than 5, indicating that we may have chosen a q value which may be too small. Ljung-Box test reports a p-value of 5.285e-11, meaning we reject the hypothesis that the residuals are distributed as a white noise.

```{r Examine PACF of AR2 model}
pacf(resAR2) # PACF not null for lags 1, 2, 3, 5 & 7
```

PACF plot not null for lags 1, 2, 3, 5 & 7, indicating that we may not have chosen a large enough value of p.

## Exercise 3

Now fit an AR(10) model to Series Z.

#### a) Are the parameters significant? Examine the residuals and describe your findings.

```{r Fit AR10 model}
modelZ10 = arima(Z, order = c(10, 0, 0), include.mean = FALSE)
coeftest(modelZ10)
# first 8 paramaeters are significant
# may be due to fact that any ARMA(p, q) model with |phiK| <= 1 for all K can be approximated by an AR(k) model where k is large
```

All parameters up to $\phi_9$ & $\phi_{10}$ are significant.

```{r Look at mean & variance of AR10}
res10 = residuals(modelZ10)
mean(res10)
var(res10)
```

Plot of residuals looks to be distributed as a white noise. Mean of residuals roughly 0 & variance roughly 1.

```{r Look at qq-plot}
qqnorm(res10)
qqline(res10)
```
```{r run shapiro test for AR10}
shapiro.test(res10)
# p-value of 0.2136, fail to reject normality hypothesis at 5% significance
```

QQ-Plot seems fine as well, p-value on the Shapiro-Wilk test of 0.2136 means we do not reject the normality hypothesis on the residuals at 5% significance level.

```{r Plot residuals of AR10}
plot(res10, fitted(modelZ10)) # no obvious pattern in residuals
```

There is no obvious pattern in the plot of residuals vs fitted values.

```{r Look at ACF plot of AR10}
acf(res10) # acf of residuals null for all lags
Box.test(res10, lag = 20, type = "Ljung-Box", fitdf = 10)
# p-value = 0.8274. Fail to reject hypothesis that residuals distributed as a white noise.
```

ACF plot of the residuals null for all lags, indicating that we have chosen a sufficient value of q. The Ljung-Box test reports a p-value of 0.8274, meaning we fail to reject null hypothesis that residuals are distributed as a white noise.

```{r Examine PACF plot of AR10}
pacf(res10) # pacf of residuals null for all lags
```

PACF plot shows null values for all lags, indicating that we have chosen a sufficient value of p.

#### b) Why might this model fit the Series well?

This model may suit the series well as any ARMA(p, 1) can be approximated by an AR(K) model for K large enough. As we are using a large value of p (10) for our model, the approximation works well.